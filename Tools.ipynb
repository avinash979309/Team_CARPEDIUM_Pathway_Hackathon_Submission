{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW67CRgrjv76"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "from pydantic import Field, PrivateAttr\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.callbacks.manager import CallbackManagerForToolRun\n",
        "from langchain.tools import tool\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "from typing import Optional\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_core.callbacks import CallbackManagerForToolRun\n",
        "\n",
        "class PDFTextExtractorTool(BaseTool):\n",
        "    name: str = \"PDFTextExtractor\"\n",
        "    description: str = \"Extracts relevant data from a PDF file located at the specified path. Provide the path and query.\"\n",
        "\n",
        "    def _run(self, query: str, pdf_path: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
        "            # Load the PDF file\n",
        "            loader = PyPDFLoader(pdf_path)\n",
        "            docs = loader.load()\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=500, chunk_overlap=200, add_start_index=True)\n",
        "            all_splits = text_splitter.split_documents(docs)\n",
        "            vector_store = InMemoryVectorStore(embeddings)\n",
        "            ids = vector_store.add_documents(documents=all_splits)\n",
        "            results = vector_store.similarity_search(query)\n",
        "            print(results[0])\n",
        "            return results[0]\n",
        "\n",
        "\n",
        "extract_tool = PDFTextExtractorTool()\n",
        "\n",
        "\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        ")\n",
        "\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "import os\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"f9bec0683ce3cf7380f98d08f08e2b55666b4e37b13f074f663f7f154c480443\"\n",
        "\n",
        "@tool\n",
        "def google_search(query: str):\n",
        "    \"\"\"Search Google for recent and realtime results.\"\"\"\n",
        "    search = SerpAPIWrapper()\n",
        "    return search.run(query)\n",
        "\n",
        "\n",
        "import os\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "def download_pdfs(urls: list, folder_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Downloads PDFs from a given list of URLs and saves them to the specified folder.\n",
        "\n",
        "    :param urls: List of URLs of the PDF files.\n",
        "    :param folder_path: The folder where the PDFs should be saved.\n",
        "    \"\"\"\n",
        "    # Ensure the folder exists\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    for index, url in enumerate(urls, start=1):\n",
        "        try:\n",
        "            # Extract the filename from the URL or use a default name\n",
        "            filename = url.split('/')[-1]\n",
        "            if not filename.endswith('.pdf'):\n",
        "                filename = f\"file_{index}.pdf\"  # Fallback filename\n",
        "\n",
        "            save_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            # Download and save the PDF\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Raise an error for HTTP issues\n",
        "            with open(save_path, 'wb') as file:\n",
        "                file.write(response.content)\n",
        "            print(f\"PDF successfully downloaded and saved to {save_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {url}: {e}\")\n",
        "\n",
        "\n",
        "folder_path = \"/content/sample_data/pdfs\"\n",
        "\n",
        "\n",
        "from googlesearch import search\n",
        "\n",
        "\n",
        "@tool\n",
        "def downloader_tool(query: str, num_results: int = 3):\n",
        "    \"\"\"Downloads the online documents from across the internet.\n",
        "\n",
        "    Args:\n",
        "        query: The search query.\n",
        "        num_results: The maximum number of search results to consider (default: 10).\n",
        "    \"\"\"\n",
        "    # 1. Perform a web search for relevant PDFs (limit to top 10)\n",
        "    search_results = search(f\"{query} filetype:pdf\", num=num_results)\n",
        "\n",
        "    # Convert the generator to a list and return the top results\n",
        "    urls = [url for _, url in zip(range(num_results), search_results)]\n",
        "\n",
        "    download_pdfs(urls, folder_path)\n",
        "\n",
        "    print(\"---HHAAAAA\")\n",
        "\n",
        "\n",
        "\n",
        "@tool\n",
        "def online_retriever_tool():\n",
        "    \"\"\"Does nothing.A dummy tool that does nothing but satisfies the tool requirement.\"\"\"\n",
        "    return \" \"\n",
        "\n",
        "@tool\n",
        "def iterative_consolidation_tool(initial_context: str, max_iterations: int = 2) -> str:\n",
        "    \"\"\"Tool to get consolidated information from initial context.\"\"\"\n",
        "    consolidation_chain = LLMChain(llm=llm, prompt=consolidation_prompt)\n",
        "    context = initial_context\n",
        "\n",
        "    # Debug: Print the initial context received\n",
        "    print(\"------------------\")\n",
        "    # print(\"\\n Initial Context Passed to Tool:\\n\", context)\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        # Run iterative consolidation\n",
        "        context = consolidation_chain.run({\"context\": context})\n",
        "\n",
        "        # Debug: Print context after each iteration\n",
        "        print(f\" Iteration {i + 1} Context:\\n\", context)\n",
        "        print(\"------------------\")\n",
        "\n",
        "    return context\n",
        "\n",
        "\n",
        "@tool\n",
        "def NoOpTool():\n",
        "    \"\"\"Does nothing.A dummy tool that does nothing but satisfies the tool requirement.\"\"\"\n",
        "    return \" \"\n",
        "\n",
        "\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain.tools import Tool\n",
        "\n",
        "class FinancialAbbreviationTool:\n",
        "    def __init__(self, document_path: str):\n",
        "        self.document_path = document_path\n",
        "        self.db = self._load_documents()\n",
        "\n",
        "    def _load_documents(self):\n",
        "        raw_documents = TextLoader(self.document_path).load()\n",
        "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "        documents = text_splitter.split_documents(raw_documents)\n",
        "        return FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "    def retrieve_full_form(self, abbreviation: str) -> str:\n",
        "        results = self.db.similarity_search(abbreviation)\n",
        "        if results:\n",
        "            return results[0].page_content  # Return the most relevant match\n",
        "        return f\"Full form for '{abbreviation}' not found.\"\n",
        "\n",
        "abbreviation_tool = FinancialAbbreviationTool(\"/content/sample_data/Jargon_collection.txt\")\n",
        "\n",
        "retrieve_abbreviation_tool = Tool(\n",
        "    name=\"RetrieveFullForms\",\n",
        "    func=abbreviation_tool.retrieve_full_form,\n",
        "    description=\"Use this tool to retrieve the full form of abbreviations or shorthand terms in financial context.\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@tool\n",
        "def generate_subquestions(query: str,file_path : str):\n",
        "    \"\"\"\n",
        "    Tool to handle queries that require a complex retrieval.\n",
        "    It can answer any question from simple to complex.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    global final_sub_responses\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    file_path=file_path\n",
        "    # Define the system prompt dynamically based on the number of sub-questions\n",
        "    system = f\"\"\"You are a helpful assistant designed to generate actionable sub-questions related to a given input query. Your primary goal is to break down complex queries into smaller, focused, and answerable sub-questions that can be independently addressed by LLMs or other tools.\n",
        "\n",
        "### Instructions:\n",
        "1. **Purpose**: Ensure each sub-question is specific and independently answerable to extract relevant information. The goal is to collect all necessary pieces of information for answering the user's main query.\n",
        "\n",
        "2. **Relevance and Focus**:\n",
        "   - Sub-questions must directly relate to the user's input query.\n",
        "   - Avoid asking the user for additional information. Instead, focus on generating questions that the LLM or tools can answer using external data or documents.\n",
        "   - Sub-questions should cover various aspects of the input query comprehensively but concisely.\n",
        "\n",
        "3. **Avoid Asking Back**: Do not create sub-questions that ask the user for clarification or additional details. For example:\n",
        "   - **Avoid**: \"What specific financial metrics are you interested in?\"\n",
        "   - **Instead**: \"What were Nykaa's total revenues in the last quarter of 2023?\"\n",
        "\n",
        "4. **Examples**:\n",
        "   - Input Query: \"Nykaa's last quarter financial report.\"\n",
        "     - Sub-Questions:\n",
        "       - \"What was Nykaa's revenue in the last quarter of 2023?\"\n",
        "       - \"What were Nykaa's expenses in the last quarter of 2023?\"\n",
        "       - \"What was Nykaa's profit in the last quarter of 2023?\"\n",
        "       - \"What is the overall performance of Nykaa in the last quarter of 2023?\"\n",
        "\n",
        "   - Input Query: \"Impact of AI on healthcare.\"\n",
        "     - Sub-Questions:\n",
        "       - \"What are the recent advancements in AI for disease detection?\"\n",
        "       - \"How is AI used in personalized medicine?\"\n",
        "       - \"What is the role of AI in drug discovery?\"\n",
        "       - \"What are the benefits of AI in robotic surgeries?\"\n",
        "       - \"What are the risks of using AI in healthcare?\"\n",
        "\n",
        "### Output Format:\n",
        "- Generate sub-questions in a list format.\n",
        "- Ensure the sub-questions are clear, concise, and directly actionable.\n",
        "- Do not exceed 5 sub-questions.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Initialize the structured model (example: a model capable of sub-question generation)\n",
        "    structured_model = llm.with_structured_output(Questions)\n",
        "\n",
        "    # Generate the sub-questions\n",
        "    response = structured_model.invoke(\n",
        "        [SystemMessage(content=system), HumanMessage(content=query)]\n",
        "    )\n"
      ]
    }
  ]
}