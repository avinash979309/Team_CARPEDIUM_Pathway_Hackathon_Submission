{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xsMunXy8QoYT"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7d1lS8AQxRg",
        "outputId": "6748bf94-6156-4441-f065-062fa635a9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (0.6.8)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.30)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (0.3.33)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langgraph langchain_community langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3pd02Y8-Q68V"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
        "os.environ[\"TAVILY_API_KEY\"] =\"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJlhPpqdRA5I",
        "outputId": "4ed87b69-67fd-4d21-8098-5a77bd317b65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.7)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20250506)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwXsVLPcRC2A",
        "outputId": "68a6a055-1025-496e-d3ad-6ac61be48bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_anthropic in /usr/local/lib/python3.12/dist-packages (0.3.21)\n",
            "Requirement already satisfied: anthropic<1.0.0,>=0.69.0 in /usr/local/lib/python3.12/dist-packages (from langchain_anthropic) (0.69.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.76 in /usr/local/lib/python3.12/dist-packages (from langchain_anthropic) (0.3.76)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain_anthropic) (2.11.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic<1.0.0,>=0.69.0->langchain_anthropic) (4.15.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (0.4.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.4.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic<1.0.0,>=0.69.0->langchain_anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain_anthropic) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain_anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1.0.0,>=0.69.0->langchain_anthropic) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain_anthropic) (2.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWqBISIxRI2r",
        "outputId": "02c6cc17-9aff-4509-d5a8-8f9d066cb83f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_chroma in /usr/local/lib/python3.12/dist-packages (0.2.6)\n",
            "Requirement already satisfied: langchain-core>=0.3.76 in /usr/local/lib/python3.12/dist-packages (from langchain_chroma) (0.3.76)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain_chroma) (2.0.2)\n",
            "Requirement already satisfied: chromadb>=1.0.20 in /usr/local/lib/python3.12/dist-packages (from langchain_chroma) (1.1.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (2.11.9)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma) (0.35.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.23.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (0.22.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (1.75.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (0.17.4)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb>=1.0.20->langchain_chroma) (4.25.1)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.76->langchain_chroma) (0.4.28)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.76->langchain_chroma) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.76->langchain_chroma) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb>=1.0.20->langchain_chroma) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain_chroma) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain_chroma) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain_chroma) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain_chroma) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.20->langchain_chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.76->langchain_chroma) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain_chroma) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain_chroma) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain_chroma) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain_chroma) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (2.32.5)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (0.10)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.76->langchain_chroma) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.76->langchain_chroma) (0.25.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.20->langchain_chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain_chroma) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain_chroma) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain_chroma) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.20->langchain_chroma) (0.58b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain_chroma) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain_chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain_chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain_chroma) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain_chroma) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain_chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain_chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.20->langchain_chroma) (0.35.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.20->langchain_chroma) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb>=1.0.20->langchain_chroma) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain_chroma) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain_chroma) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain_chroma) (1.1.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.20->langchain_chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.20->langchain_chroma) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (3.4.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.20->langchain_chroma) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain_chroma) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_pwwy-L8rur",
        "outputId": "4cb4e03c-c0cb-4ffc-fcac-9b73f18184a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.30)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.76)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.28)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dKS_V5ygG_H9"
      },
      "outputs": [],
      "source": [
        "%pip install -qU \"langchain-community>=0.2.11\" tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCrHtAccUMiE",
        "outputId": "b3e6175b-fdce-4186-909c-4cbb2d49b733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgNyv4J8ImA6",
        "outputId": "824ec005-c825-4c88-e362-b34a5b43ee6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.12/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ZaXLlEKij9",
        "outputId": "2ce03892-9078-4e4f-b5c8-5279cf2d183c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Zo6jf0e0RFdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7f7bc8-36ee-441d-fd81-9d4db357a77b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your API key: \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your API key: \")\n",
        "model = chat = llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HtVjyZGxRPg8"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Cf6LzN4eKspm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYicsb0PRjr7",
        "outputId": "812aba7d-f057-4b1f-8aaa-69e515a7f07d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 35027, which is longer than the specified 1000\n"
          ]
        }
      ],
      "source": [
        "from typing import Optional\n",
        "from pydantic import Field, PrivateAttr\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.callbacks.manager import CallbackManagerForToolRun\n",
        "from langchain.tools import tool\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "from typing import Optional\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_core.callbacks import CallbackManagerForToolRun\n",
        "\n",
        "class PDFTextExtractorTool(BaseTool):\n",
        "    name: str = \"PDFTextExtractor\"\n",
        "    description: str = \"Extracts relevant data from a PDF file located at the specified path. Provide the path and query.\"\n",
        "\n",
        "    def _run(self, query: str, pdf_path: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
        "            # Load the PDF file\n",
        "            loader = PyPDFLoader(pdf_path)\n",
        "            docs = loader.load()\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=50, chunk_overlap=5, add_start_index=True)\n",
        "            all_splits = text_splitter.split_documents(docs)\n",
        "            vector_store = InMemoryVectorStore(embeddings)\n",
        "            ids = vector_store.add_documents(documents=all_splits)\n",
        "            results = vector_store.similarity_search(query)\n",
        "            print(results[0])\n",
        "            return results[0]\n",
        "\n",
        "\n",
        "extract_tool = PDFTextExtractorTool()\n",
        "\n",
        "\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(\n",
        "    max_results=5,\n",
        "    search_depth=\"advanced\",\n",
        "    include_answer=True,\n",
        "    include_raw_content=True,\n",
        "    include_images=True,\n",
        ")\n",
        "\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "import os\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"f9bec0683ce3cf7380f98d08f08e2b55666b4e37b13f074f663f7f154c480443\"\n",
        "\n",
        "@tool\n",
        "def google_search(query: str):\n",
        "    \"\"\"Search Google for recent and realtime results.\"\"\"\n",
        "    search = SerpAPIWrapper()\n",
        "    return search.run(query)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "def download_pdfs(urls: list, folder_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Downloads PDFs from a given list of URLs and saves them to the specified folder.\n",
        "\n",
        "    :param urls: List of URLs of the PDF files.\n",
        "    :param folder_path: The folder where the PDFs should be saved.\n",
        "    \"\"\"\n",
        "    # Ensure the folder exists\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    for index, url in enumerate(urls, start=1):\n",
        "        try:\n",
        "            # Extract the filename from the URL or use a default name\n",
        "            filename = url.split('/')[-1]\n",
        "            if not filename.endswith('.pdf'):\n",
        "                filename = f\"file_{index}.pdf\"  # Fallback filename\n",
        "\n",
        "            save_path = os.path.join(folder_path, filename)\n",
        "\n",
        "            # Download and save the PDF\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Raise an error for HTTP issues\n",
        "            with open(save_path, 'wb') as file:\n",
        "                file.write(response.content)\n",
        "            print(f\"PDF successfully downloaded and saved to {save_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {url}: {e}\")\n",
        "\n",
        "\n",
        "folder_path = \"/content/sample_data/pdfs\"\n",
        "\n",
        "\n",
        "from googlesearch import search\n",
        "\n",
        "\n",
        "@tool\n",
        "def downloader_tool(query: str, num_results: int = 3):\n",
        "    \"\"\"Downloads the online documents from across the internet.\n",
        "\n",
        "    Args:\n",
        "        query: The search query.\n",
        "        num_results: The maximum number of search results to consider (default: 10).\n",
        "    \"\"\"\n",
        "    # 1. Perform a web search for relevant PDFs (limit to top 10)\n",
        "    search_results = search(f\"{query} filetype:pdf\", num=num_results)\n",
        "\n",
        "    # Convert the generator to a list and return the top results\n",
        "    urls = [url for _, url in zip(range(num_results), search_results)]\n",
        "\n",
        "    download_pdfs(urls, folder_path)\n",
        "\n",
        "    print(\"---\")\n",
        "\n",
        "\n",
        "\n",
        "@tool\n",
        "def online_retriever_tool():\n",
        "    \"\"\"Does nothing.A dummy tool that does nothing but satisfies the tool requirement.\"\"\"\n",
        "    return \" \"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "\n",
        "\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "consolidation_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "### Instructions:\n",
        "**Use Only the Provided Information**:\n",
        "- Do not source or refer to any additional data.\n",
        "- Rely exclusively on the content of `information_from_multiple_sources`.\n",
        "\n",
        "Task: Consolidate knowledge collected from various sources as described:\n",
        "1. Cluster passages with consistent information.\n",
        "2. Separate conflicting information into distinct clusters.\n",
        "3. Exclude irrelevant information.\n",
        "\n",
        "Context so far: {context}\n",
        "\n",
        "Consolidated Context after iteration:\n",
        "\"\"\",\n",
        "    input_variables=[\"context\"],\n",
        ")\n",
        "\n",
        "@tool\n",
        "def iterative_consolidation_tool(initial_context: str, max_iterations: int = 2) -> str:\n",
        "    \"\"\"Tool to get consolidated information from initial context.\"\"\"\n",
        "    consolidation_chain = LLMChain(llm=llm, prompt=consolidation_prompt)\n",
        "    context = initial_context\n",
        "\n",
        "    # Debug: Print the initial context received\n",
        "    print(\"------------------\")\n",
        "    # print(\"\\n Initial Context Passed to Tool:\\n\", context)\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        # Run iterative consolidation\n",
        "        context = consolidation_chain.run({\"context\": context})\n",
        "\n",
        "        # Debug: Print context after each iteration\n",
        "        print(f\" Iteration {i + 1} Context:\\n\", context)\n",
        "        print(\"------------------\")\n",
        "\n",
        "    return context\n",
        "\n",
        "\n",
        "@tool\n",
        "def NoOpTool():\n",
        "    \"\"\"Does nothing.A dummy tool that does nothing but satisfies the tool requirement.\"\"\"\n",
        "    return \" \"\n",
        "\n",
        "def make_retriever_prompt(file_path: str, suffix: str) -> str:\n",
        "    return (\n",
        "        f\"You are a data retrieval agent tasked with extracting relevant information from a file located at '{file_path}'.\\n\"\n",
        "        \"### Instructions:\\n\"\n",
        "        \"- Always use the 'pdf_extract' tool to extract relevant data to the user's query.\\n\"\n",
        "        \"- Pass the file located at the provided path  to the tool.\\n\"\n",
        "        \"- If the information extracted from the tool is irrelevant to the query, return: '----'\"\n",
        "        \"- If the file path is invalid or the file cannot be processed, return : '------'\"\n",
        "        f\"file path is : {file_path}\"\n",
        "        f\"{suffix}\"\n",
        "    )\n",
        "\n",
        "def make_internal_prompt(suffix: str) -> str:\n",
        "    return (\n",
        "        \"answer the query of user\"\n",
        "        \"if no relevant answer is found to the user's query, return the  message: '-----'\"\n",
        "        f\"{suffix}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def make_searcher_prompt(suffix: str) -> str:\n",
        "    return (\n",
        "        \"You are an independent web search agent tasked with extracting relevant information from web search.\"\n",
        "        \" You have access to two tools for this purpose:\"\n",
        "        \"\\n\\n\"\n",
        "        \"1. *google_search Tool*: Use this tool for queries related to stock market, finance, and real-time financial news.\"\n",
        "        \" It will provide information on stock prices, market trends, and other financial data from Google Finance.\"\n",
        "        \"\\n\\n\"\n",
        "        \"2. *Tavily Tool*: Use this tool for all other general queries that are not specifically related to stock market or finance.\"\n",
        "        \" It is designed to help with various types of information across different domains.\"\n",
        "        \"\\n\\n\"\n",
        "        \"Instructions:\"\n",
        "        \"- For finance-related or stock market queries, you must use the *google_search Tool* to retrieve relevant stock market data or financial news.\"\n",
        "        \"- For all other queries, use the *Tavily Tool* to extract general information.\"\n",
        "        \"- If the information extracted from the tool(s) is irrelevant to the query, return the  message: '-----' \"\n",
        "        f\"\\n{suffix}\"\n",
        "    )\n",
        "def make_astute_prompt(suffix: str,information_from_multiple_sources: str) -> str:\n",
        "    return (\n",
        "        f\"\"\"\n",
        "You are an Astute Knowledge Consolidation Agent responsible for synthesizing information from the provided input and producing a reliable and concise answer.\n",
        "\n",
        "### Context:\n",
        "- You will receive all necessary information as a single string: information_from_multiple_sources.\n",
        "\n",
        "### Instructions:\n",
        "1. *Use Only the Provided Information*:\n",
        "   - Do not source or refer to any additional data.\n",
        "   - Rely exclusively on the content of information_from_multiple_sources.\n",
        "\n",
        "2. *Process the Information*:\n",
        "   - Always Pass the entire string {information_from_multiple_sources} into the iterative_consolidation_tool as initial_context to generate a consolidated version of the information.\n",
        "\n",
        "3. *Deliver the Final Answer*:\n",
        "   - Return the full output you got from tool from last 'iteration' , doesn't matter how lengthy.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "        + suffix\n",
        "    )\n",
        "\n",
        "def make_final_prompt(user_query: str, final_sub_responses: str) -> str:\n",
        "    return f\"\"\"\n",
        "You are a Financial Agent tasked with answering user queries using *only* the provided information.\n",
        "\n",
        "### Instructions:\n",
        "- Analyze the user's query: \"{user_query}\".\n",
        "- Use *only* the information provided in: {final_sub_responses}.\n",
        "- Do not rely on external knowledge, assumptions, or sources outside the given data.\n",
        "\n",
        "### Rules:\n",
        "1. If the information in {final_sub_responses} directly addresses the query, provide a clear and detailed answer.\n",
        "2. If the information is incomplete or irrelevant to the query, acknowledge this honestly.\n",
        "3. Include any numerical data, percentages, or financial terms from {final_sub_responses} that are relevant to the query.\n",
        "\n",
        "### Response Format:\n",
        "- Provide a *concise and accurate* response based strictly on {final_sub_responses}.\n",
        "-Return Your answer\n",
        "\"\"\"\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "def make_decider_agent_prompt(file_path: Optional[str] = None) -> str:\n",
        "    # Remove the file_path_instruction entirely\n",
        "    # and directly instruct the agent to call the 'generate_subquestions' tool\n",
        "    return f\"\"\"\n",
        "You are a Hybrid Intelligent Agent capable of responding to user queries with two distinct actions:\n",
        "\n",
        "### Task:\n",
        "1. *Handle Basic Queries*:\n",
        "   - For queries that are simple, conversational, or general in nature and can be answered directly without tools, respond to the user immediately and concisely.\n",
        "   - Examples of basic queries:\n",
        "     - \"What is the capital of France?\"\n",
        "     - \"How's the weather today?\" (if no real-time access is required)\n",
        "     - \"Tell me a joke.\"\n",
        "\n",
        "2. *Delegate Complex Queries*:\n",
        "   - If the query requires advanced reasoning, tool assistance, or additional processing (e.g., using provided data, generating sub-questions), pass the query to the 'generate_subquestions' tool to process the query. # Changed this line\n",
        "   - The agent's job is only to call the tool and totally stop after calling it. The tool will handle everything required for the response.\n",
        "\n",
        "### How to Decide:\n",
        "- *Basic Query*: Can be answered with general knowledge, conversational ability, or straightforward logic.\n",
        "- *Complex Query*: Requires access to tools, processing information, or generating sub-questions.\n",
        "\n",
        "### Tool Access:\n",
        "- You have access to the following tool:\n",
        "  - 'generate_subquestions': Use this tool to break down complex queries into sub-questions and process information to generate a detailed response.\n",
        "\n",
        "### Response Format:\n",
        "1. *For Basic Queries*:\n",
        "   - Respond directly with the prefix: *DIRECT RESPONSE:*\n",
        "   - Example:\n",
        "\n",
        "     DIRECT RESPONSE: The capital of France is Paris.\n",
        "\n",
        "\n",
        "2. *For Complex Queries*:\n",
        "   - Use the generate_subquestions tool with the full query or necessary context.\n",
        "   - Totally stop after calling the tool.\n",
        "\n",
        "### Guidelines:\n",
        "- Avoid making assumptions beyond general knowledge for basic queries.\n",
        "- Delegate complex queries without attempting to answer them yourself.\n",
        "\n",
        "### Example Scenarios:\n",
        "#### User Query: \"What is 2 + 2?\"\n",
        "- *Action*: Respond directly.\n",
        "- *Response*: \"DIRECT RESPONSE: 2 + 2 equals 4.\"\n",
        "\n",
        "#### User Query: \"Analyze the impact of global warming on marine biodiversity.\"\n",
        "- *Action*: Call generate_subquestions tool with the query.\n",
        "- *Action Format*:\n",
        "   - If file path provided: Include {file_path} in the tool invocation.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_online_documents_retriever_prompt(suffix: str) -> str:\n",
        "    return (\n",
        "    f\"\"\"\n",
        "You are an Online Documents Retriever Agent tasked with retrieving information relevant to a user's query from documents sourced online. You have access to two tools for this purpose:\n",
        "\n",
        "### Workflow:\n",
        "1. **Download Relevant Documents**:\n",
        "   - Use the `downloader_tool` to download documents relevant to the user's query.\n",
        "   - These documents will be saved in a folder named **'online_documents'**.\n",
        "\n",
        "2. **Retrieve Similar Information**:\n",
        "   - Use the `online_retriever_tool` to perform a similarity search across all documents in the **'online_documents'** folder.\n",
        "   - Extract information related to the user's query based on embeddings and similarity search.\n",
        "\n",
        "3. **Filter and Output Relevant Information**:\n",
        "   - Analyze the extracted information to determine which parts are relevant to the user's query.\n",
        "   - Provide a concise and accurate answer using only the relevant information.\n",
        "   - If no relevant information is found, respond: **'No relevant information is found across the online documents.'**\n",
        "\n",
        "### Instructions:\n",
        "- Always use the two tools in the specified sequence:\n",
        "  1. First call the `downloader_tool` to download documents.\n",
        "  2. Then call the `online_retriever_tool` to search for relevant information.\n",
        "- Do not fabricate or infer information not found in the retrieved documents.\n",
        "- Ensure the final response is clear, concise, and directly addresses the user's query.\n",
        "- If the user's query cannot be addressed using the downloaded documents, transparently communicate this.\n",
        "\n",
        "### Tools:\n",
        "1. **downloader_tool**:\n",
        "   - Function: Downloads relevant documents from the web based on the query.\n",
        "   - Input: User's query string.\n",
        "   - Output: Confirmation of documents downloaded to the **'online_documents'** folder.\n",
        "\n",
        "2. **online_retriever_tool**:\n",
        "   - Function: Performs similarity search on the documents in the **'online_documents'** folder.\n",
        "   - Input: User's query string.\n",
        "   - Output: Extracted information relevant to the query, or confirmation if no relevant data is found.\n",
        "\n",
        "### Response Format:\n",
        "1. **For Successful Retrieval**:\n",
        "   - Begin with the prefix: **RETRIEVED INFORMATION:**\n",
        "   - Provide the relevant information extracted from the documents.\n",
        "   - Example:\n",
        "     ```\n",
        "     RETRIEVED INFORMATION:\n",
        "     - The impact of climate change includes rising sea levels and more frequent extreme weather events (Source: Document X).\n",
        "     ```\n",
        "\n",
        "2. **For No Relevant Information**:\n",
        "   - Respond with: **'----'**\n",
        "\n",
        "### Example Workflow:\n",
        "#### User Query:\n",
        "\"What are the latest advancements in AI for healthcare?\"\n",
        "\n",
        "#### Agent Actions:\n",
        "1. Call `downloader_tool` with query: \"Latest advancements in AI for healthcare.\"\n",
        "   - Response: \"Documents have been downloaded to 'online_documents'.\"\n",
        "\n",
        "2. Call `online_retriever_tool` with query: \"Latest advancements in AI for healthcare.\"\n",
        "   - Response: Extracted information from relevant documents.\n",
        "\n",
        "3. Provide the final response:\n",
        "\n",
        "\"\"\"\n",
        "+ suffix\n",
        "    )\n",
        "\n",
        "\n",
        "online_documents_agent = create_react_agent(\n",
        "llm,\n",
        "tools=[downloader_tool,online_retriever_tool],\n",
        "prompt=make_searcher_prompt(\"You can download the online documents and retrieve relevant information from them using the provided tools.\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "search_agent = create_react_agent(\n",
        "llm,\n",
        "tools=[tavily_tool,google_search],\n",
        "prompt=make_searcher_prompt(\"You can only search using the tools and return the answer\"),\n",
        "\n",
        ")\n",
        "\n",
        "internal_agent = create_react_agent(\n",
        "llm,\n",
        "tools=[NoOpTool],\n",
        "prompt=make_internal_prompt(\"you can only answer using the model's internal knowledge\"),\n",
        ")\n",
        "\n",
        "\n",
        "## Block 2\n",
        "\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain.tools import Tool\n",
        "\n",
        "class FinancialAbbreviationTool:\n",
        "    def __init__(self, document_path: str):\n",
        "        self.document_path = document_path\n",
        "        self.db = self._load_documents()\n",
        "\n",
        "    def _load_documents(self):\n",
        "        raw_documents = TextLoader(self.document_path).load()\n",
        "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "        documents = text_splitter.split_documents(raw_documents)\n",
        "        return FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "    def retrieve_full_form(self, abbreviation: str) -> str:\n",
        "        results = self.db.similarity_search(abbreviation)\n",
        "        if results:\n",
        "            return results[0].page_content  # Return the most relevant match\n",
        "        return f\"Full form for '{abbreviation}' not found.\"\n",
        "\n",
        "abbreviation_tool = FinancialAbbreviationTool(\"/content/sample_data/Jargon_collection.txt\")\n",
        "\n",
        "retrieve_abbreviation_tool = Tool(\n",
        "    name=\"RetrieveFullForms\",\n",
        "    func=abbreviation_tool.retrieve_full_form,\n",
        "    description=\"Use this tool to retrieve the full form of abbreviations or shorthand terms in financial context.\"\n",
        ")\n",
        "\n",
        "\n",
        "def make_financial_agent_prompt(suffix: str) -> str:\n",
        "    return f\"\"\"\n",
        "    You are a Financial Context Agent responsible for analyzing and processing user queries effectively.\n",
        "\n",
        "    ## Instructions:\n",
        "    1. **Determine Context**: Analyze the query to identify its context (e.g., financial, legal, medical, general).\n",
        "       - If the context is not financial, return the query unchanged.\n",
        "    2. **Identify Abbreviations**: If the context is financial, detect any abbreviations or shorthand terms present in the query.\n",
        "    3. **Retrieve Full Forms**: Use the 'RetrieveFullForms' tool to get the full forms of any abbreviations detected.\n",
        "    4. **Augment Query**: Replace abbreviations in the query with their full forms to make it more precise and understandable.If not found full forms of any abbreviation ,let them remain same in query.\n",
        "    5. **Final Response**: Return the final query **only**, without any tool usage logs or explanations.\n",
        "\n",
        "    ## Strict Rules:\n",
        "    - Do not include any tool usage logs, intermediate reasoning, or explanations in the output.\n",
        "    - The output must be a plain string representing the final query only.\n",
        "    - Any response containing metadata, tool invocation details, or explanations will be considered invalid.\n",
        "\n",
        "    ## Query:\n",
        "    {suffix}\n",
        "    \"\"\"\n",
        "\n",
        "financial_agent = create_react_agent(\n",
        "    llm,\n",
        "    tools=[retrieve_abbreviation_tool],\n",
        "    prompt=make_financial_agent_prompt(\"your task is to create the augmented query if requierd given theat the context of query is financial\"),\n",
        ")\n",
        "\n",
        "stored_responses={}\n",
        "string_representation=\"\"\n",
        "\n",
        "#### Block 1\n",
        "\n",
        "import threading\n",
        "import time\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "\n",
        "# Define a pydantic model to enforce the output structure\n",
        "class Questions(BaseModel):\n",
        "    questions: List[str] = Field(\n",
        "        description=\"A list of sub-questions related to the input query.\"\n",
        "    )\n",
        "\n",
        "final_sub_responses = \"\"\n",
        "\n",
        "@tool\n",
        "def generate_subquestions(query: str,file_path : str):\n",
        "    \"\"\"\n",
        "    Tool to handle queries that require a complex retrieval.\n",
        "    It can answer any question from simple to complex.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    global final_sub_responses\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    file_path=file_path\n",
        "    # Define the system prompt dynamically based on the number of sub-questions\n",
        "    system = f\"\"\"You are a helpful assistant designed to generate actionable sub-questions related to a given input query. Your primary goal is to break down complex queries into smaller, focused, and answerable sub-questions that can be independently addressed by LLMs or other tools.\n",
        "\n",
        "### Instructions:\n",
        "1. **Purpose**: Ensure each sub-question is specific and independently answerable to extract relevant information. The goal is to collect all necessary pieces of information for answering the user's main query.\n",
        "\n",
        "2. **Relevance and Focus**:\n",
        "   - Sub-questions must directly relate to the user's input query.\n",
        "   - Avoid asking the user for additional information. Instead, focus on generating questions that the LLM or tools can answer using external data or documents.\n",
        "   - Sub-questions should cover various aspects of the input query comprehensively but concisely.\n",
        "\n",
        "3. **Avoid Asking Back**: Do not create sub-questions that ask the user for clarification or additional details. For example:\n",
        "   - **Avoid**: \"What specific financial metrics are you interested in?\"\n",
        "   - **Instead**: \"What were Nykaa's total revenues in the last quarter of 2023?\"\n",
        "\n",
        "4. **Examples**:\n",
        "   - Input Query: \"Nykaa's last quarter financial report.\"\n",
        "     - Sub-Questions:\n",
        "       - \"What was Nykaa's revenue in the last quarter of 2023?\"\n",
        "       - \"What were Nykaa's expenses in the last quarter of 2023?\"\n",
        "       - \"What was Nykaa's profit in the last quarter of 2023?\"\n",
        "       - \"What is the overall performance of Nykaa in the last quarter of 2023?\"\n",
        "\n",
        "   - Input Query: \"Impact of AI on healthcare.\"\n",
        "     - Sub-Questions:\n",
        "       - \"What are the recent advancements in AI for disease detection?\"\n",
        "       - \"How is AI used in personalized medicine?\"\n",
        "       - \"What is the role of AI in drug discovery?\"\n",
        "       - \"What are the benefits of AI in robotic surgeries?\"\n",
        "       - \"What are the risks of using AI in healthcare?\"\n",
        "\n",
        "### Output Format:\n",
        "- Generate sub-questions in a list format.\n",
        "- Ensure the sub-questions are clear, concise, and directly actionable.\n",
        "- Do not exceed 5 sub-questions.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Initialize the structured model (example: a model capable of sub-question generation)\n",
        "    structured_model = llm.with_structured_output(Questions)\n",
        "\n",
        "    # Generate the sub-questions\n",
        "    response = structured_model.invoke(\n",
        "        [SystemMessage(content=system), HumanMessage(content=query)]\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for question in response.questions:\n",
        "      x=financial_agent.invoke({\"messages\":[HumanMessage(content=question)]})\n",
        "      new_query= x[\"messages\"][-1].content\n",
        "      print(\"---------------\")\n",
        "      print(f\"Subquery :    {new_query}\")\n",
        "      print(\"---------------\")\n",
        "\n",
        "      x=internal_agent.invoke({\"messages\":[HumanMessage(content=new_query)]})\n",
        "      result=x[\"messages\"][-1].content\n",
        "      print(\"---------------\")\n",
        "      print(f\"source1st : {result}\")\n",
        "      print(\"---------------\")\n",
        "      stored_responses['Source_1']=[result]\n",
        "\n",
        "\n",
        "      x=search_agent.invoke({\"messages\":[HumanMessage(content=new_query)]})\n",
        "      result=x[\"messages\"][-1].content\n",
        "      print(\"---------------\")\n",
        "      print(f\"source2nd : {result}\")\n",
        "      print(\"---------------\")\n",
        "      stored_responses['Source_2']=[result]\n",
        "\n",
        "      retriever_agent = create_react_agent(\n",
        "      llm,\n",
        "      tools=[extract_tool],\n",
        "      prompt=make_retriever_prompt(\"You can only retrieve and answer from the file\",file_path),\n",
        "      )\n",
        "\n",
        "      x=retriever_agent.invoke({\"messages\":[HumanMessage(content=new_query)]})\n",
        "      result=x[\"messages\"][-1].content\n",
        "      print(\"---------------\")\n",
        "      print(f\"source3rd : {result}\")\n",
        "      print(\"---------------\")\n",
        "      stored_responses['Source_3']=[result]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # print(f\"dictionary is : {stored_responses}\")\n",
        "\n",
        "      string_representation = '\\n'.join(f\"{key}: {value}\" for key, value in stored_responses.items())\n",
        "\n",
        "      # print(f\"string is {string_representation}\")\n",
        "\n",
        "\n",
        "      astute_agent = create_react_agent(\n",
        "      llm,\n",
        "      tools=[iterative_consolidation_tool],\n",
        "      prompt=make_astute_prompt(\n",
        "          \"Generate the final deliverable answer using the information received from the sources.\",\n",
        "          string_representation))\n",
        "\n",
        "      x=astute_agent.invoke({\"messages\":[HumanMessage(content=new_query)]})\n",
        "      result=x[\"messages\"][-1].content\n",
        "      final_sub_responses += result\n",
        "      print(\"---------------\")\n",
        "      print(f\"SUBANSWERS COLLECTIONS: {final_sub_responses}\")\n",
        "      print(\"---------------\")\n",
        "\n",
        "\n",
        "    x=online_documents_agent.invoke({\"messages\":[HumanMessage(content=query)]})\n",
        "    print(\"----------------- Online agent content is ----\")\n",
        "    result=x[\"messages\"][-1].content\n",
        "    final_sub_responses += result\n",
        "    print(f\"source4th : {result}\")\n",
        "    print(f\"SUBANSWERS COLLECTIONS FINAL: {final_sub_responses}\")\n",
        "    print(\"-----------------\")\n",
        "\n",
        "\n",
        "    final_agent=create_react_agent(\n",
        "    llm,\n",
        "    tools=[NoOpTool],\n",
        "    prompt=make_final_prompt(\"Answer thoroughly the user's query using the provided information as string.\",final_sub_responses),\n",
        "\n",
        ")\n",
        "\n",
        "    x=final_agent.invoke({\"messages\":[HumanMessage(content=query)]})\n",
        "\n",
        "    print(\"---------------\")\n",
        "    print(query)\n",
        "    final_result=x[\"messages\"][-1].content\n",
        "    print(f\"Final Cumulative Answer: {final_result}\")\n",
        "    print(\"---------------\")\n",
        "\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def run_function():\n",
        "\n",
        "  from google.colab import files\n",
        "\n",
        "  # Step 1: Ask the user if they want to upload a document\n",
        "  user_input = input(\"Do you want to upload a document? (yes/no): \").strip().lower()\n",
        "\n",
        "  # Step 2: Handle the user's choice\n",
        "  if user_input in ['yes', 'y']:\n",
        "      # Create the folder if it doesn't exist\n",
        "      folder_name = 'input_documents'\n",
        "      if not os.path.exists(folder_name):\n",
        "          os.makedirs(folder_name)\n",
        "\n",
        "      # Upload the file\n",
        "      print(\"Please upload your document:\")\n",
        "      uploaded = files.upload()\n",
        "\n",
        "      # Save the uploaded file to the folder and store the file path\n",
        "      for filename in uploaded.keys():\n",
        "          file_path = os.path.join(folder_name, filename)  # Construct the file path\n",
        "          with open(file_path, 'wb') as f:\n",
        "              f.write(uploaded[filename])  # Save the file to the folder\n",
        "          print(f\"File uploaded and saved at: {file_path}\")\n",
        "  else:\n",
        "      print(\"No document uploaded.\")\n",
        "\n",
        "\n",
        "\n",
        "  decider_agent=create_react_agent(\n",
        "      llm,\n",
        "      tools=[generate_subquestions],\n",
        "      prompt=make_decider_agent_prompt(file_path=None),\n",
        "\n",
        "\n",
        "  )\n",
        "\n",
        "\n",
        "  A=decider_agent.invoke({\"messages\":[HumanMessage(content=user_query)]})\n",
        "  result=A[\"messages\"][-1].content\n",
        "  print(result)\n",
        "\n",
        "\n",
        "\n",
        "#here query will be asked and fromhere the full model would work\n",
        "\n",
        "\n",
        "user_query=input(\"Enter query please:\")\n",
        "if user_query:\n",
        "  run_function()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qh2TZTVBpWCj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}